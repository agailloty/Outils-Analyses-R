---
title: "Analyse en composantes principales"
author: "Axel-Cleris Gailloty"
date: "2024-02-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	fig.width = 6,
	warning = FALSE,
	comment = "", 
	message = FALSE
)
options(digits = 2)
```

```{r message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
fifa22 <- read_csv("https://raw.githubusercontent.com/agailloty/Outils-Analyses-R/main/dataset/fifa_players_22.csv")
```

# L'analyse en composantes principales

L'analyse en composantes principales (ACP) est une méthode statistique utilisée pour simplifier des données complexes en les transformant en un ensemble de variables moins nombreux, appelées composantes principales. Son objectif principal est de réduire la dimensionnalité des données tout en préservant autant que possible l'information originale. En termes simples, l'ACP essaie de trouver les directions dans lesquelles les données sont les plus étalées. Ces directions correspondent aux axes le long desquels les données varient le plus. En réorganisant les données selon ces axes, l'ACP permet de représenter les données de manière plus concise tout en conservant les tendances et les structures importantes. Cela rend plus facile l'interprétation des données et peut aider à identifier les modèles cachés ou les relations entre les variables. En résumé, l'ACP est une méthode puissante pour explorer et simplifier des ensembles de données complexes en les visualisant dans un espace de dimensions réduites.

variable synthétique, composante, axe = dimension.

```{r}
fifa300 <- fifa22[1:300,]
player_names <- fifa300$short_name
fifa300 <- select(fifa300, -short_name)
fifa300 <- as.data.frame(fifa300)
rownames(fifa300) <- player_names
```

Dans le contexte de l'Analyse en Composantes Principales (ACP) :

Les variables actives, également appelées variables quantitatives actives, sont les variables sur lesquelles l'ACP est réalisée. Ce sont les variables qui sont utilisées pour calculer les composantes principales et pour lesquelles on souhaite visualiser ou interpréter les résultats. Elles sont généralement continues et mesurées sur une échelle numérique.

Les variables quantitatives illustratives sont des variables supplémentaires qui peuvent être incluses dans l'analyse pour fournir une perspective supplémentaire ou pour aider à l'interprétation des résultats. Bien qu'elles ne soient pas utilisées pour calculer les composantes principales, elles sont affichées sur les graphiques de l'ACP pour voir comment elles se comportent par rapport aux variables actives.

Les variables qualitatives illustratives, parfois appelées variables catégorielles ou facteurs illustratifs, sont des variables non numériques qui décrivent des catégories ou des groupes. Elles ne sont pas utilisées pour calculer les composantes principales, mais elles peuvent être incluses dans l'analyse pour colorer ou étiqueter les observations sur les graphiques de l'ACP, ce qui peut aider à identifier des tendances ou des relations entre les catégories.

## Préparer les colonnes du jeu de données

Pour calculer les composantes principales nous utilisons la fonction PCA qui vient du package FactoMineR. Cette fonction s'attend à ce que nous lui fournissons en paramètre une liste des positions des variables quantitatives illustratives et des variables qualitatives illustratives. 
Pour ce faire nous allons dans un premier définir des listes qui variables que nous voulons considérer comme quantitatives illustratives et comme qualitatives illustratives.

```{r}
var_actives <- c("age", "height_cm", "weight_kg", "shooting", "passing", "dribbling", 
"defending", "physic", "attacking_crossing", "attacking_finishing", 
"attacking_heading_accuracy", "attacking_short_passing", "attacking_volleys", 
"skill_dribbling", "skill_curve", "skill_fk_accuracy", "skill_long_passing", 
"skill_ball_control", "movement_acceleration", "movement_sprint_speed", 
"movement_agility", "movement_reactions", "movement_balance", 
"power_shot_power", "power_jumping", "power_stamina", "power_strength", 
"power_long_shots", "mentality_aggression", "mentality_interceptions", 
"mentality_positioning", "mentality_vision", "mentality_penalties", 
"mentality_composure", "defending_marking_awareness", "defending_standing_tackle", 
"defending_sliding_tackle", "goalkeeping_diving", "goalkeeping_handling", 
"goalkeeping_reflexes")
```


```{r}
var_quanti_illustratives <- c("overall", "potential", "value_eur", "wage_eur","league_level", "international_reputation")

var_quali_illustratives <- c("preferred_foot", "body_type")

fifa300 <- fifa300[, c(var_actives, var_quanti_illustratives, var_quali_illustratives)]

```

Une fois ces listes définies nous allons déterminer les positions de ces variables dans le jeu de données.  

```{r}
idx_var_quanti_illustratives <- match(var_quanti_illustratives, colnames(fifa300))
idx_var_quali_illustratives <- match(var_quali_illustratives, colnames(fifa300))
```



# Réaliser une ACP avec FactoMineR

```{r}
# Charger la librairie FactoMineR
library(FactoMineR)
library(factoextra) # Pour représenter graphiques
```

Pour appeler la fonction PCA, il faut lui passer un jeu de données symbolisé par X, dans notre cas X = fifa300, scale.unit = TRUE pour centrer et réduire chaque variable quantitative du jeu de données. Centrer une variable revient à lui retirer sa moyenne et la réduire revient à la diviser par son écart-type. Ensuite on précise les positions des variables quantitatives illustratives (quanti.sup) et des variables qualitatives illustratives (quali.sup)

```{r}
premiere_acp <- PCA(X = fifa300, scale.unit = TRUE, quanti.sup = idx_var_quanti_illustratives, 
                    quali.sup = idx_var_quali_illustratives, graph = FALSE)
```

```{r}
summary(premiere_acp, ncp = 5)
```

Dans ce tableau la variance exprime la valeur propre de chaque dimension. Selon la règle de Kaiser, nous devons retenir que les dimensions qui ont une valeur propre (donc variance) supérieure à 1. Ce qui fait que dans le présent cas nous pouvons retenir 7 dimensions.

La ligne variance cumulée nous permet de savoir le % d'informations expliquées par un nombre donné de composantes. Par exemple si on retient deux composantes (Dim1 et Dim2) nous expliquons 55.875 % de l'information contenue dans les variables.

La règle de Kaiser ne nous force pas à analyser toutes les dimensions, elle nous aide à retenir seulement celles qui pourraient être pertinentes.

Dans notre cas nous allons retenir 4 composantes qui nous permettent d'expliquer 71.5% de l'information.

```{r fig.height=3}
fviz_screeplot(premiere_acp, main = "% de l'information expliquée par chaque composante.")
```

## Interprétation des composantes

Une composante, dans le contexte de l'analyse en composantes principales (ACP), est une nouvelle variable qui est une combinaison linéaire des variables originales de manière à capturer la variation maximale des données. Chaque composante est une direction dans l'espace des variables originales qui représente une certaine quantité d'information sur les données. Les composantes sont ordonnées en fonction de la quantité de variation qu'elles capturent, de sorte que la première composante représente la plus grande variation des données, la deuxième composante représente la deuxième plus grande variation, et ainsi de suite. Les composantes permettent de réduire la dimensionnalité des données tout en conservant l'essentiel de l'information, ce qui facilite l'interprétation et l'analyse des données.

## Cercle des corrélations

```{r fig.height=8, fig.width=10}
fviz_pca_var(premiere_acp, title = "Premier plan factoriel", repel = TRUE)
```

Le cercle de corrélation est un graphique utilisé dans l'analyse en composantes principales (ACP) pour visualiser les relations entre les variables originales et les composantes principales extraites de ces variables. Dans ce graphique, chaque variable est représentée par un vecteur dirigé à partir de l'origine du repère jusqu'à son point de coordonnées sur le cercle. La longueur de chaque vecteur représente la corrélation entre la variable correspondante et les composantes principales, tandis que l'angle entre les vecteurs reflète les relations entre les variables elles-mêmes. Le cercle de corrélation permet ainsi de visualiser la structure des données dans un espace de dimensions réduites et d'identifier les variables qui contribuent le plus à chaque composante principale.

## Etude de la première composante

```{r}
dimdesc(premiere_acp, axes = 1)
```

### Les profils des joueurs qui s'opposent sur la première composante

La première composante oppose les variables dribbling, skill_dribbling, shooting, skill_curve et skill_ball_control aux variables defending, defending_marking_awareness, defending_standing_tackle defending_standing_tackle et mentality_interceptions. 
Avec ces informations nous pouvons affirmer que la composante 1 oppose les attaquants aux défenseurs. 

Les joueurs qui ont une coordonnée positive sur cette composante ont de fortes valeurs dans les variables dribbling, skill_dribbling, shooting, skill_curve et skill_ball_control mais de faibles valeurs dans les variables defending, defending_marking_awareness, defending_standing_tackle defending_standing_tackle et mentality_interceptions. Et les individus qui ont une coordonnée négative sur la composante 1 ont de faibles valeurs dans les variables dribbling, skill_dribbling, shooting, skill_curve et skill_ball_control et de fortes valeurs dans les variables defending, defending_marking_awareness, defending_standing_tackle defending_standing_tackle et mentality_interceptions.


### Les coordonnées des joueurs sur la composante 1

Nous voyons par exmple que sur la première composante L. Messi a une coordonnée positive forte égale à 8.3.

```{r}
sort(premiere_acp$ind$coord[, 1], decreasing = TRUE)[1:15]
```
Tandis que sur cette même composante K. Manolas a une coordonnée négative égale à -12.2.

```{r}
sort(premiere_acp$ind$coord[, 1], decreasing = FALSE)[1:10]
```

La première composante oppose donc des joueurs comme ***`r names(sort(premiere_acp$ind$coord[, 1], decreasing = TRUE))[1:10]`*** à des joueurs comme ***`r names(sort(premiere_acp$ind$coord[, 1], decreasing = FALSE))[1:10]`***. 

## Etude de la seconde composante

```{r}
dimdesc(premiere_acp, axes = 2)
```
La seconde composante oppose les variables  skill_long_passing, mentality_interceptions, defending_standing_tackle, attacking_short_passing, defending_sliding_tackle aux variables weight_kg, attacking_heading_accuracy, height_cm, movement_sprint_speed, power_strength. 

Les joueurs qui ont une coordonnée positive sur cette composante ont de fortes valeurs dans les variables skill_long_passing, mentality_interceptions, defending_standing_tackle, attacking_short_passing, defending_sliding_tackle mais de faibles valeurs dans les variables defending, defending_marking_awareness, defending_standing_tackle defending_standing_tackle et mentality_interceptions. Et les individus qui ont une coordonnée négative sur la composante 2 ont de faibles valeurs dans les variables weight_kg, attacking_heading_accuracy, height_cm, movement_sprint_speed, power_strength.

### Les coordonnées des joueurs sur la composante 2

Sur la composante 2 M. Verratti a une coordonnée positive forte égale à 5.5.

```{r}
sort(premiere_acp$ind$coord[, 2], decreasing = TRUE)[1:10]
```
Tandis que D. Zapata a une coordonnées négative de -6.6.

```{r}
sort(premiere_acp$ind$coord[, 2], decreasing = FALSE)[1:10]
```

## Le plan factoriel des individus

Le plan factoriel permet de visualiser les relations entre les individus (ou observations) dans un espace de dimensions réduites. Chaque individu est représenté par un point dans ce plan. La position relative des points individuels permet d'interpréter les relations entre eux : les individus proches sont similaires en termes de leurs valeurs sur les variables.

```{r fig.height=7, fig.width=9}
fviz_pca_ind(premiere_acp, labelsize = 2,
             select.ind = list(cos2 = 0.6))
```


## Le cosinus carré et la contribution

### Le cosinus carré

Le cosinus carré, également connu sous le nom de qualité de représentation, est une mesure utilisée dans l'analyse en composantes principales (ACP) pour évaluer à quel point chaque variable est bien représentée par les composantes principales extraites. Il mesure la corrélation entre les variables originales et les composantes principales. Plus le cosinus carré est proche de 1, meilleure est la représentation de la variable par les composantes principales. Cela signifie que la variable est bien alignée avec les axes des composantes principales et qu'elle contribue significativement à l'explication de la variance des données. 
En revanche, un cosinus carré proche de 0 indique que la variable est mal représentée par les composantes principales et qu'elle contribue peu à l'explication de la variance.

> Le cos2 est calculé comme le carré de la corrélation entre les coordonnées de la variable dans l'espace original et les coordonnées projetées sur un axe factoriel spécifique.

Le tableau suivant nous permet d'interpréter la valeur du cosinus carré pour toutes les variables sur les 4 premières dimensions. Nous pouvons observer par exemple que la variable age a un casinus carré très proche de 0 sur les composantes 1, 2 et 4. Cela signifie que l'age n'a aucun impact sur ces composantes. Nous pouvons affirmer que l'age n'influence en rien le fait qu'un joueur soit attaquant ou défenseur (composante 1).

```{r}
premiere_acp$var$cos2[, 1:4]
```

### La contribution 

La contribution mesure l'importance de chaque variable dans la formation de chaque composante principale. Elle est calculée en prenant en compte à la fois la corrélation entre la variable et la composante et la variance de la variable. Les variables avec une contribution élevée sont celles qui ont le plus d'impact sur la formation de la composante correspondante. Les contributions élevées peuvent indiquer que la variable est importante pour la structure de la composante, tandis que les contributions faibles indiquent que la variable a moins d'influence.

```{r}
premiere_acp$var$contrib[, 1:4]
```

```{r}
fviz_pca_contrib(premiere_acp, axes = 1, choice = "var")
```

```{r}
fviz_pca_contrib(premiere_acp, axes = 2, choice = "var")
```



## Etude de la composante 3

```{r}
dimdesc(premiere_acp, axes = 3)
```


### Les coordonnées des joueurs sur la composante 3

```{r}
sort(premiere_acp$ind$coord[, 3], decreasing = TRUE)[1:10]
```

```{r}
sort(premiere_acp$ind$coord[, 3], decreasing = FALSE)[1:10]
```

## Etude de la composante 4

```{r}
dimdesc(premiere_acp, axes = 4)
```

### Les coordonnées des joueurs sur la composante 4

```{r}
sort(premiere_acp$ind$coord[, 4], decreasing = TRUE)[1:10]
```
```{r}
sort(premiere_acp$ind$coord[, 4], decreasing = FALSE)[1:10]
```

```{r fig.height=8, fig.width=10}
fviz_pca_var(premiere_acp, title = "Second plan factoriel", repel = TRUE, axes = c(3,4))
```


## Le plan factoriel des individus

```{r fig.height=7, fig.width=9}
fviz_pca_ind(premiere_acp, labelsize = 2, axes = c(3,4),
             select.ind = list(cos2 = 0.2))
```


## La classification ascendante hiérarchique

La Classification Ascendante Hiérarchique (CAH) est une méthode d'analyse des données utilisée pour regrouper des individus ou des variables similaires en clusters ou en groupes homogènes. Elle fonctionne en regroupant de manière progressive les individus ou les variables en clusters en fonction de leur similarité.

Nous utilisons la fonction HPCP pour réaliser une classification hiérarchique sur le jeu de données.  Nous spécifions le paramètre nb.clust = -1 pour laisser R décider du nombre optimal de classes.

```{r}
classif <- HCPC(premiere_acp, nb.clust = -1, graph = FALSE)
```

Pour connaître le nombre de classes 

```{r}
unique(classif$data.clust$clust)
```
Dans le présent cas, R a déterminé que le nombre optimal de classes dans lesquelles regrouper les joueurs de football est de 3. 

## Dendogramme des classes

Un dendrogramme est un diagramme arborescent utilisé dans l'analyse de regroupement, tel que la Classification Ascendante Hiérarchique (CAH), pour visualiser la structure hiérarchique des regroupements dans un ensemble de données. Il représente graphiquement la manière dont les individus sont regroupés en clusters en fonction de leur similarité.


```{r}
fviz_dend(classif, show_labels = FALSE)
```

## Description des classes

### Description des clusters par les composantes

Lors de l'analyse en composante principale nous avons étudié les différentes composantes et nous avons une idée de ce que mesure chaque composante. Nous aimerons maintenant comprendre la répartition des individus dans les différents clusters grâce aux composantes principales.

Le tableau suivant nous liste les composantes principales qui expliquent de manière significative la variance des individus.

```{r}
classif$desc.axes$quanti.var
```

Pour grouper les joueurs en clusters, 4 composantes sont retenues.


### Description du cluster 1

```{r}
classif$desc.axes$quanti$`1`
```
Le tableau précédent nous montre quelles dimensions caractérisent les mieux les individus du cluster 1. Dans cet exemple ce sont les dimensions 1 et 4 qui caractérisent les individus du cluster 1.
Les individus de ce cluster ont une coordonnées moyenne de -0.67 sur la dimension 4 tandis que les tous les individus ont pris globalement ont une moyenne de -4.8e-15 soit très proche de 0.

Les individus du cluster 1 ont en moyenne une coordonnée de -7.16 sur la dimension 1 tandis que la moyenne générale des autres individus est de 3.3e-15. 

```{r}
options(scipen = 4, digits = 4)
classif$desc.var$quanti$`1`
```

```{r}
rownames(fifa300)[classif$data.clust$clust == 1]
```



Ce sont les dimensions (composantes) 1 et 4 qui caractérisent les individus qui se trouvent dans ce cluster.

**v.test** : La valeur de la statistique. Elle sert à calculer le **p.value** (la probabilité critique). Si la valeur absolue du v.test (|v.test|) est supérieure à 1.96 alors on dit que la composante est statistiquement significative pour caractériser les individus. 

**Mean in category** : C'est la valeur que prennent les individus de ce cluster. 

**Overall mean** : C'est la valeur moyenne de tout l'échantillon.

**sd in category** : L'écart moyen entre les individus du cluster.

**Overall sd** : L'écart moyen entre les individus de l'échantillon.

### Description du cluster 2

```{r}
classif$desc.axes$quanti$`2`
```

```{r}
classif$desc.var$quanti$`2`
```

```{r}
rownames(fifa300)[classif$data.clust$clust == 2]
```


### Description du cluster 3

```{r}
classif$desc.axes$quanti$`3`
```

```{r}
classif$desc.var$quanti$`3`
```

```{r}
rownames(fifa300)[classif$data.clust$clust == 3]
```

## Visualisation des clusters

```{r fig.height=15, fig.width=25}
fviz_cluster(classif, select.ind = list(cos2 = 0.6), ellipse = FALSE)
```

```{r fig.height=15, fig.width=25}
fviz_cluster(classif, select.ind = list(cos2 = 0.6), axes = c(3, 4), ellipse = FALSE)
```

## Les individus parongon et spécifiques

### Les individus parangon  

Le but de la classification ascendante hiérarchique c'est de regrouper les individus qui se ressemblent le plus (minimiser la variance intra cluster) et faire en sorte que chaque cluster diffère d'un autre (maximiser la variance entre chaque cluster).

Les individus parangon sont les individus qui se rapprochent le plus du centre de chaque cluster. Ce sont les individus "moyens" ou "typiques" de chaque cluster. C'est eux qui caractérisent le mieux le cluster étudié.

### Les individus spéciques

Ce sont les individus les plus éloignés du centre du cluster. On aurait pu les mettre dans un autre cluster. Ils peuvent être à la frontière d'un ou plusieurs clusters.


```{r}
classif$desc.ind$para
```


```{r}
classif$desc.ind$dist
```

# Annexes

## Définitions des termes 

**Le cercle des corrélations** :Le cercle de corrélation est un graphique utilisé qui sert à visualiser les relations entre les variables originales et les composantes principales extraites de ces variables. Dans ce graphique, chaque variable est représentée par un vecteur dirigé à partir de l'origine du repère jusqu'à son point de coordonnées sur le cercle. La longueur de chaque vecteur représente la corrélation entre la variable correspondante et les composantes principales, tandis que l'angle entre les vecteurs reflète les relations entre les variables elles-mêmes. 

**Cla/Mod** : Le nombre des individus de la modalité se trouvant dans cette classe.

```{r}
table(classif$data.clust$clust, classif$data.clust$preferred_foot)
```

Dans la classe 1 : 

11 individus sont gauchers, 46 autres sont droitiers. Il y a donc 11 + 46 = 57 personnes dans la classe .

Dans la classe 2 29 individus sont gauchers et 85 sont droitiers : 85 + 29 = 114

Dans la classe 3 : 39 gauchers, 90 droitiers = 129 individus. 

Somme individus des 3 classes = 57 + 114 + 129 = 300.

Nombre d'individus de la classe 1 possédant la modalité gaucher.

P(G/Class = 1) = 11 / 57 => 19.29%
P(Droitier / Class = 1) = 46/57 => 80.7%

**Mod/Cla** : Le nombre d'individus de la classe présentant cette modalité. 

Probabilité d'être de la classe 1 et présentant la modalité gaucher 

Nombre total des gauchers : 11 + 29 + 39 = 79
Nb Gaucher = 79

P(Class = 1 / G) = 11 / 79 => 13.92%

Nb Droitier = 221

P(Class = 2 / D) = 85 / 221 => 38.46%
